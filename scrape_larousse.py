#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script pour r√©cup√©rer tous les mots du dictionnaire Larousse
"""

import requests
import re
import time
import json
from typing import Set, List
from urllib.parse import urljoin, quote
import os

class LarousseScraper:
    """Classe pour r√©cup√©rer les mots du dictionnaire Larousse"""
    
    def __init__(self):
        self.base_url = "https://www.larousse.fr"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.words = set()
        
    def get_alphabet_links(self) -> List[str]:
        """R√©cup√®re les liens vers toutes les lettres de l'alphabet"""
        try:
            print("üîç R√©cup√©ration des liens alphabet...")
            url = f"{self.base_url}/dictionnaires/francais"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                # Chercher les liens vers les lettres
                pattern = r'href="(/dictionnaires/francais/[a-z])"'
                matches = re.findall(pattern, response.text)
                
                alphabet_links = []
                for match in matches:
                    full_url = urljoin(self.base_url, match)
                    alphabet_links.append(full_url)
                
                print(f"‚úÖ {len(alphabet_links)} liens alphabet trouv√©s")
                return alphabet_links
            else:
                print(f"‚ùå Erreur HTTP: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration des liens: {e}")
            return []
    
    def get_words_from_letter(self, letter_url: str) -> Set[str]:
        """R√©cup√®re tous les mots commen√ßant par une lettre"""
        words = set()
        
        try:
            print(f"üìñ R√©cup√©ration des mots pour: {letter_url}")
            response = self.session.get(letter_url, timeout=10)
            
            if response.status_code == 200:
                # Chercher les mots dans la page
                # Pattern pour les liens vers les d√©finitions de mots
                word_pattern = r'href="/dictionnaires/francais/[^"]*">([^<]+)</a>'
                matches = re.findall(word_pattern, response.text)
                
                for match in matches:
                    word = match.strip().lower()
                    # Nettoyer le mot
                    word = re.sub(r'[^\w\s-]', '', word)
                    if word and len(word) > 1 and word.isalpha():
                        words.add(word)
                
                print(f"   ‚úÖ {len(words)} mots trouv√©s")
                
                # Chercher s'il y a une pagination
                pagination_pattern = r'href="([^"]*page=\d+[^"]*)"'
                pagination_matches = re.findall(pagination_pattern, response.text)
                
                # Traiter les pages suivantes
                for page_link in pagination_matches[:5]:  # Limiter √† 5 pages par lettre
                    full_page_url = urljoin(letter_url, page_link)
                    page_words = self.get_words_from_page(full_page_url)
                    words.update(page_words)
                    time.sleep(1)  # Pause pour √™tre respectueux
                
            else:
                print(f"   ‚ùå Erreur HTTP: {response.status_code}")
                
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
        
        return words
    
    def get_words_from_page(self, page_url: str) -> Set[str]:
        """R√©cup√®re les mots d'une page sp√©cifique"""
        words = set()
        
        try:
            response = self.session.get(page_url, timeout=10)
            
            if response.status_code == 200:
                word_pattern = r'href="/dictionnaires/francais/[^"]*">([^<]+)</a>'
                matches = re.findall(word_pattern, response.text)
                
                for match in matches:
                    word = match.strip().lower()
                    word = re.sub(r'[^\w\s-]', '', word)
                    if word and len(word) > 1 and word.isalpha():
                        words.add(word)
                        
        except Exception as e:
            print(f"   ‚ùå Erreur page: {e}")
        
        return words
    
    def scrape_all_words(self) -> Set[str]:
        """R√©cup√®re tous les mots du Larousse"""
        print("üöÄ D√©but de la r√©cup√©ration des mots Larousse...")
        
        # R√©cup√©rer les liens alphabet
        alphabet_links = self.get_alphabet_links()
        
        if not alphabet_links:
            print("‚ùå Impossible de r√©cup√©rer les liens alphabet")
            return set()
        
        all_words = set()
        
        # Traiter chaque lettre
        for i, letter_url in enumerate(alphabet_links, 1):
            print(f"\nüìö Lettre {i}/{len(alphabet_links)}")
            letter_words = self.get_words_from_letter(letter_url)
            all_words.update(letter_words)
            
            print(f"   üìä Total accumul√©: {len(all_words)} mots")
            
            # Pause entre les lettres
            time.sleep(2)
        
        return all_words
    
    def save_words(self, words: Set[str], filename: str = "dictionnaire_larousse.txt"):
        """Sauvegarde les mots dans un fichier"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                for word in sorted(words):
                    f.write(word + '\n')
            
            print(f"‚úÖ {len(words)} mots sauvegard√©s dans {filename}")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la sauvegarde: {e}")

def scrape_common_french_words():
    """R√©cup√®re des mots fran√ßais courants depuis d'autres sources"""
    print("üîÑ R√©cup√©ration de mots fran√ßais courants...")
    
    # Liste de mots fran√ßais courants
    common_words = {
        # Articles et d√©terminants
        "le", "la", "les", "un", "une", "des", "ce", "cette", "ces", "mon", "ma", "mes",
        "ton", "ta", "tes", "son", "sa", "ses", "notre", "votre", "leur", "leurs",
        
        # Pronoms
        "je", "tu", "il", "elle", "nous", "vous", "ils", "elles", "me", "te", "se",
        "lui", "leur", "moi", "toi", "soi", "eux", "elles", "ceci", "cela", "√ßa",
        
        # Conjonctions
        "et", "ou", "mais", "donc", "car", "ni", "or", "puis", "ensuite", "alors",
        "quand", "si", "comme", "que", "qui", "quoi", "o√π", "pourquoi", "comment",
        
        # Pr√©positions
        "√†", "de", "en", "dans", "sur", "sous", "avec", "sans", "pour", "par", "vers",
        "chez", "entre", "contre", "devant", "derri√®re", "pr√®s", "loin", "autour",
        
        # Adverbes
        "tr√®s", "trop", "peu", "beaucoup", "assez", "plus", "moins", "bien", "mal",
        "vite", "lentement", "maintenant", "hier", "aujourd'hui", "demain", "toujours",
        "jamais", "souvent", "rarement", "parfois", "ici", "l√†", "ailleurs", "partout",
        
        # Verbes courants
        "√™tre", "avoir", "faire", "aller", "venir", "voir", "dire", "savoir", "pouvoir",
        "vouloir", "devoir", "prendre", "donner", "mettre", "tenir", "venir", "partir",
        "arriver", "rester", "passer", "sortir", "entrer", "monter", "descendre",
        "ouvrir", "fermer", "commencer", "finir", "continuer", "arr√™ter", "changer",
        
        # Adjectifs courants
        "grand", "petit", "bon", "mauvais", "beau", "laid", "nouveau", "vieux", "jeune",
        "chaud", "froid", "long", "court", "large", "√©troit", "lourd", "l√©ger", "fort",
        "faible", "rapide", "lent", "facile", "difficile", "possible", "impossible",
        "vrai", "faux", "juste", "clair", "sombre", "propre", "sale", "sec",
        "mouill√©", "plein", "vide", "ouvert", "ferm√©", "libre", "occup√©", "calme",
        "bruyant", "doux", "dur", "souple", "rigide", "lisse", "rugueux",
        
        # Noms courants
        "homme", "femme", "enfant", "personne", "groupe", "famille", "ami", "travail",
        "maison", "ville", "pays", "monde", "temps", "jour", "nuit", "matin", "soir",
        "semaine", "mois", "ann√©e", "heure", "minute", "seconde", "maintenant",
        "eau", "air", "feu", "terre", "soleil", "lune", "√©toile", "ciel", "mer",
        "montagne", "for√™t", "champ", "route", "chemin", "pont", "porte", "fen√™tre",
        "mur", "toit", "sol", "plafond", "escalier", "couloir", "salle", "chambre",
        "cuisine", "bureau", "magasin", "√©cole", "h√¥pital", "banque",
        "restaurant", "h√¥tel", "th√©√¢tre", "cin√©ma", "mus√©e", "parc", "jardin",
        "voiture", "train", "avion", "bateau", "v√©lo", "moto", "bus", "m√©tro",
        "livre", "journal", "lettre", "t√©l√©phone", "radio", "t√©l√©vision", "musique",
        "film", "photo", "image", "couleur", "forme", "taille", "poids", "prix",
        "argent", "monnaie", "billet", "pi√®ce", "carte", "ch√®que", "facture",
        "nom", "pr√©nom", "√¢ge", "adresse", "email", "date", "lieu",
        "raison", "cause", "effet", "r√©sultat", "probl√®me", "solution", "question",
        "r√©ponse", "exemple", "cas", "situation", "√©tat", "condition", "niveau",
        "qualit√©", "quantit√©", "nombre", "total", "partie", "ensemble", "groupe",
        "syst√®me", "m√©thode", "technique", "proc√©d√©", "processus", "√©tape", "phase",
        "p√©riode", "moment", "instant", "fois"
    }
    
    return common_words

def main():
    """Fonction principale"""
    
    print("=" * 70)
    print("SCRAPING DU DICTIONNAIRE LAROUSSE")
    print("=" * 70)
    
    # Option 1: Scraping Larousse (peut prendre du temps)
    print("\n1. Scraping complet du Larousse (long)")
    print("2. Utiliser des mots fran√ßais courants (rapide)")
    print("3. Combiner les deux")
    
    choice = input("\nVotre choix (1-3): ").strip()
    
    all_words = set()
    
    if choice == "1":
        # Scraping Larousse
        scraper = LarousseScraper()
        larousse_words = scraper.scrape_all_words()
        all_words.update(larousse_words)
        scraper.save_words(larousse_words, "dictionnaire_larousse.txt")
        
    elif choice == "2":
        # Mots courants
        common_words = scrape_common_french_words()
        all_words.update(common_words)
        print(f"‚úÖ {len(common_words)} mots courants r√©cup√©r√©s")
        
    elif choice == "3":
        # Combiner les deux
        print("üîÑ R√©cup√©ration des mots courants...")
        common_words = scrape_common_french_words()
        all_words.update(common_words)
        
        print("üîÑ Scraping Larousse...")
        scraper = LarousseScraper()
        larousse_words = scraper.scrape_all_words()
        all_words.update(larousse_words)
        
    else:
        print("‚ùå Choix invalide")
        return
    
    # Sauvegarder le dictionnaire final
    if all_words:
        with open("dictionnaire_francais.txt", 'w', encoding='utf-8') as f:
            for word in sorted(all_words):
                f.write(word + '\n')
        
        print(f"\nüéâ DICTIONNAIRE CR√â√â AVEC SUCC√àS !")
        print(f"üìä Total: {len(all_words)} mots fran√ßais")
        print(f"üíæ Sauvegard√© dans: dictionnaire_francais.txt")
        
        # Afficher quelques exemples
        sample_words = list(all_words)[:20]
        print(f"üìù Exemples: {', '.join(sample_words)}")
        
    else:
        print("‚ùå Aucun mot r√©cup√©r√©")

if __name__ == "__main__":
    main()
